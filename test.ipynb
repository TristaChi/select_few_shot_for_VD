{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from call_llm import *\n",
    "from learn_from_mistake import *\n",
    "from prompts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "msg = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                                {\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    "response = call_openai_gpt(msg)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Few-Shot Set:\n",
      "('int x = 0;', 0)\n",
      "('char *ptr; free(ptr);', 1)\n",
      "('int *p; p = malloc(10);', 0)\n"
     ]
    }
   ],
   "source": [
    "lfm_initial_few_shot = [\n",
    "    (\"int x = 0;\", 0),   # NO\n",
    "    (\"char *ptr; free(ptr);\", 1)  # YES\n",
    "]\n",
    "\n",
    "lfm_training_data = [\n",
    "    (\"int *p; p = malloc(10);\", 0),\n",
    "    (\"char *s; strcpy(s, 'Hello');\", 1),\n",
    "    (\"int x = 5; x++;\", 0),\n",
    "    (\"free(NULL);\", 0),\n",
    "    (\"int *arr = malloc(10 * sizeof(int)); arr[10] = 5;\", 1)\n",
    "]\n",
    "\n",
    "lfm_max_few_shot_size = 5\n",
    "\n",
    "# Run the updated function\n",
    "lfm_updated_few_shot = lfm_learn_from_mistakes(\n",
    "    training_data=lfm_training_data,\n",
    "    few_shot_set=lfm_initial_few_shot,\n",
    "    max_few_shot_size=lfm_max_few_shot_size,\n",
    "    prompt_template=lfm_PROMPT_TEMPLATE  # Pass the template explicitly\n",
    ")\n",
    "\n",
    "print(\"Updated Few-Shot Set:\")\n",
    "for example in lfm_updated_few_shot:\n",
    "    print(example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for new code snippet: (1) YES: A security vulnerability detected.\n",
      "Nearest Neighbors for Few-Shot Learning:\n",
      "('int x = 5; x++;', 0)\n",
      "('int *arr = malloc(10 * sizeof(int)); arr[10] = 5;', 1)\n",
      "('char *ptr; free(ptr);', 1)\n",
      "\n",
      "GPT-4o Prediction for Query Instance:\n",
      "YES\n"
     ]
    }
   ],
   "source": [
    "from learn_from_nearest_neighbors import *\n",
    "\n",
    "# New test example (not seen during training)\n",
    "new_code_snippet = \"memcpy(dest, src, strlen(src));\"  # Buffer overflow risk, should be YES\n",
    "\n",
    "# Run the model using the updated few-shot examples\n",
    "predicted_label = call_openai_gpt_few_shot(\n",
    "    system_msg=lfm_SYSTEM_MSG,\n",
    "    # few_shot_set=[(code, \"YES\" if lbl == 1 else \"NO\") for code, lbl in lfm_updated_few_shot],  # Convert labels\n",
    "    few_shot_set=[],  # Convert labels\n",
    "    user_question=lfm_PROMPT_TEMPLATE.format(code=new_code_snippet),\n",
    "    prompt_template=lfm_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "print(f\"Prediction for new code snippet: {predicted_label}\")# Mock encoder model for testing\n",
    "class MockEncoder:\n",
    "    def encode(self, demonstration_set, instance):\n",
    "        return np.random.rand(10)  # Random vector for simplicity\n",
    "\n",
    "# Instantiate the encoder\n",
    "encoder_model = MockEncoder()\n",
    "\n",
    "# Example dataset (function snippets with labels)\n",
    "training_data = [\n",
    "    (\"int x = 0;\", 0),\n",
    "    (\"char *ptr; free(ptr);\", 1),\n",
    "    (\"int *p; p = malloc(10);\", 0),\n",
    "    (\"char *s; strcpy(s, 'Hello');\", 1),\n",
    "    (\"int x = 5; x++;\", 0),\n",
    "    (\"free(NULL);\", 0),\n",
    "    (\"int *arr = malloc(10 * sizeof(int)); arr[10] = 5;\", 1)\n",
    "]\n",
    "\n",
    "# Initialize LFNN model with training data\n",
    "t = 4  # Demonstration set size\n",
    "lfnn_model = LFNN(training_data, t, encoder_model)\n",
    "\n",
    "# Query instance (new function to classify)\n",
    "query_instance = \"memcpy(dest, src, strlen(src));\"\n",
    "\n",
    "# Get k nearest neighbors\n",
    "k = 3\n",
    "nearest_neighbors = lfnn_model.get_nearest_neighbors(query_instance, k)\n",
    "\n",
    "# Use nearest neighbors for LLM prediction\n",
    "prediction = lfnn_predict(\n",
    "    nearest_neighbors=nearest_neighbors,\n",
    "    query_instance=query_instance,\n",
    "    prompt_template=lfm_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"Nearest Neighbors for Few-Shot Learning:\")\n",
    "for example in nearest_neighbors:\n",
    "    print(example)\n",
    "\n",
    "print(f\"\\nGPT-4o Prediction for Query Instance:\\n{prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate GPT-2 XL Encoder into LFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangchi/opt/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors:\n",
      "('char *ptr; free(ptr);', 1)\n",
      "(\"char *s; strcpy(s, 'Hello');\", 1)\n",
      "('int *arr = malloc(10 * sizeof(int)); arr[10] = 5;', 1)\n"
     ]
    }
   ],
   "source": [
    "# Initialize LFNN with GPT-2 XL embeddings\n",
    "lfnn_model = LFNN(training_data, t=4)\n",
    "\n",
    "# Query a new function and get nearest neighbors\n",
    "query_instance = \"memcpy(dest, src, strlen(src));\"\n",
    "nearest_neighbors = lfnn_model.get_nearest_neighbors(query_instance, k=3)\n",
    "\n",
    "# Print nearest neighbors\n",
    "print(\"Nearest Neighbors:\")\n",
    "for example in nearest_neighbors:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
